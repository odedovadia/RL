defaults: base_qwen1b_squad.yaml

policy:
  max_total_sequence_length: 4096
  dtensor_cfg:
    enabled: false
  optimizer: null
  make_sequence_length_divisible_by: 1
  sequence_packing:
    enabled: true
  megatron_cfg:
    enabled: true
    converter_type: "Qwen2ForCausalLM"

data:
  add_generation_prompt: true
  train:
    dataset_name: OpenMathInstruct-2
    output_key: generated_solution
    split: train_1M
    split_validation_size: 0.05
    seed: ${sft.seed}
  validation: null
  default:
    prompt_file: examples/prompts/math.txt

logger:
  wandb:
    name: "sft-qwen1b-openmathinstruct-megatron-tp1-seqpack-8gpu"
  tensorboard:
    log_dir: "tb_logs-token-accuracy-megatron-tp1-openmathinstruct-8gpu"

cluster:
  gpus_per_node: 8
